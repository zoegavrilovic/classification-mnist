{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "mnist_test=pd.read_csv(\"mnist_test.csv\")\n",
    "mnist_train=pd.read_csv(\"mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test=np.array(mnist_test)\n",
    "mnist_test=mnist_test[mnist_test[:,0].argsort(kind='quicksort')]\n",
    "mnist_train=np.array(mnist_train)\n",
    "mnist_train=mnist_train[mnist_train[:,0].argsort(kind='quicksort')]\n",
    "X_test=mnist_test[:,1:]\n",
    "y_test=mnist_test[:,0]\n",
    "X_train=mnist_train[:,1:]\n",
    "y_train=mnist_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "some_digit = X_train[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)  #each image is 28x28=784px\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling oh yeah (some algos perform poorly when there are similar instances in a row)\n",
    "shuffle_index=np.random.permutation(59999)\n",
    "X_train, y_train=X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a binary classifier to only figure out if the digit is 5 or not\n",
    "y_train_5=(y_train==5)  #true for 5, false for other digits\n",
    "y_test_5=(y_test==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a SGD classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_classifier=SGDClassifier(random_state=42)\n",
    "sgd_classifier.fit(X_train,y_train_5)  #to guess which elements of X_train are 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_classifier.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9621481074053703\n"
     ]
    }
   ],
   "source": [
    "#cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold  #performs stratified sampling, gives a representative ratio of instances for each stratum\n",
    "from sklearn.base import clone\n",
    "skfolds=StratifiedKFold(n_splits=3, random_state=42)\n",
    "for train_index, test_index in skfolds.split(X_train,y_train_5):\n",
    "    clone_clf=clone(sgd_classifier)  #deep copy of the model in an estimator\n",
    "    X_train_folds=X_train[train_index]\n",
    "    y_train_folds=y_train_5[train_index]\n",
    "    X_test_fold=X_train[test_index]\n",
    "    y_test_fold=y_train_5[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred=clone_clf.predict(X_test_fold)\n",
    "    n_correct=sum(y_pred==y_test_fold)\n",
    "    print(n_correct/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kfold trains the model on all k-1 folds (not the one it's making predictions on), happens for each fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9639    , 0.9654    , 0.96214811])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  #doing the same as above\n",
    "cross_val_score(sgd_classifier, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "#BUT accuracy is generally not the preferred performance measure for classifiers,\n",
    "#especially when dealing with skewed datasets\n",
    "#because only about 10% of the images are 5s, so if\n",
    "#you always guess that an image is not a 5, you will be right about 90% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix-a much better way to evaluate performance of classifier\n",
    "##### true negatives | false positives\n",
    "##### -------------------------------------------\n",
    "##### false negatives| true positives\n",
    "\n",
    "#### To compute cm, must have a set of predictions to be compared to targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "c:\\users\\hp elitebook 8470p\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred=cross_val_predict(sgd_classifier, X_train, y_train_5, cv=3)\n",
    "#cross_val_predict() performs K-fold cross-validation,\n",
    "#but instead of returning the evaluation scores, \n",
    "#it returns the predictions made on each test fold\n",
    "#clean prediction-made by a model that never saw the data during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54070,   509],\n",
       "       [ 1662,  3758]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred) \n",
    "#each row: actual class\n",
    "#each column: predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of positive predictions-precision of classifier\n",
    "## precision=tp/(tp+fp)\n",
    "#### recall-sensitivity/true positive rate(TPR)-ratio of positive instances that are correctly detected by the classifier\n",
    "## recall=tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision = how many positives have been well predicted out of all predicted positives\n",
    "### recall = how many positives have been well predicted out of all actual positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.880712444340286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes y_true, y_pred\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933579335793358"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1 score= precision and recall together\n",
    "##### it is a harmonic mean of precision and recall. Regural mean treats all values equally, and harmonic mean gives more weight to low values --> a classifier will only get high f1 score if both precision and recall are high\n",
    "\n",
    "### f1=2/(1/precision+1/recall)=\n",
    "### = 2* precision*recall/(precision+recall)=\n",
    "### = tp/(tp+(fn+fp)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7758852069784248"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)\n",
    "#not always cool to have high f1 score(safe videos for kids, shoplifters)\n",
    "#increasing precision reduces recall, and vice versa = precision/recall tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn APIs:\n",
    "### https://scikit-learn.org/stable/modules/classes.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml_map.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
